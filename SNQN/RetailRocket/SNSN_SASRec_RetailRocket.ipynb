{"cells":[{"cell_type":"markdown","metadata":{"id":"Br90n0E2hw6I"},"source":["# SNQN on RetailRocket Dataset\n","\n","This notebook runs the Supervised Negative Q-learning (SNQN) model using SASRec on the Diginetica dataset. The dataset is available at **[here](https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset)**.\n","\n","For this implementation, we leverage the events data from RetailRocket and the source code in the src folder is modified from the open-source code from the [Supervised Advantage Actor-Critic for Recommender Systems](https://arxiv.org/abs/2111.03474) paper.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E6wd1xpUJVYy","outputId":"0179c8aa-e5ec-40cb-f951-0111d41e1306","executionInfo":{"status":"ok","timestamp":1671086796191,"user_tz":300,"elapsed":5802,"user":{"displayName":"Anna Dai","userId":"15954665269866891576"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting trfl\n","  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n","\u001b[K     |████████████████████████████████| 104 kB 32.2 MB/s \n","\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from trfl) (1.14.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from trfl) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from trfl) (1.21.6)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from trfl) (1.3.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from trfl) (0.1.7)\n","Installing collected packages: trfl\n","Successfully installed trfl-1.2.0\n"]}],"source":["# !pip install tensorflow\n","!pip install trfl\n","# !pip install tensorflow_probability"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cfxnc_BCJXYH","outputId":"dcd02a20-4f0f-4029-bf82-9026cfcb8c30","executionInfo":{"status":"ok","timestamp":1671087603496,"user_tz":300,"elapsed":23923,"user":{"displayName":"Anna Dai","userId":"15954665269866891576"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YplHwTlEUG7C","outputId":"9a16b416-0c33-4468-8c90-0b564fb1b1e5","executionInfo":{"status":"ok","timestamp":1671087609858,"user_tz":300,"elapsed":17,"user":{"displayName":"Anna Dai","userId":"15954665269866891576"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Duke/AIPI\n"]}],"source":["%cd drive/MyDrive/Duke/AIPI/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4YozLMDUOsa"},"outputs":[],"source":["# !git clone https://github.com/nogibjj/DRLrecommenders.git"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sacHrfggVlqm","outputId":"fb3f990b-5314-4e66-e0df-6c429dcd6102","executionInfo":{"status":"ok","timestamp":1671087692161,"user_tz":300,"elapsed":483,"user":{"displayName":"Anna Dai","userId":"15954665269866891576"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Duke/AIPI/DRLrecommenders/RetailRocket\n"]}],"source":["%cd DRLrecommenders/RetailRocket"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zexRn4xAVvXf","outputId":"08fbfc75-b881-4117-a1e3-5f10d5098760","executionInfo":{"status":"ok","timestamp":1671087637051,"user_tz":300,"elapsed":23,"user":{"displayName":"Anna Dai","userId":"15954665269866891576"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mAD\u001b[0m/  \u001b[01;34mBPR\u001b[0m/  \u001b[01;34mdata\u001b[0m/  README.md  \u001b[01;34mresources\u001b[0m/  \u001b[01;34mRetailRocket\u001b[0m/  \u001b[01;34m_tempsandbox\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"vHl173xfJVY0","executionInfo":{"status":"ok","timestamp":1671087697730,"user_tz":300,"elapsed":506,"user":{"displayName":"Anna Dai","userId":"15954665269866891576"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5EumAU03g4h","outputId":"57f3000a-0a2e-4ce7-dbe7-9e55eeb9a3d2","executionInfo":{"status":"ok","timestamp":1671087718340,"user_tz":300,"elapsed":17142,"user":{"displayName":"Anna Dai","userId":"15954665269866891576"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-12-15 07:01:44.174601: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"]}],"source":["!python src/preprocess_rr.py"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"QrOHiVoIJVY0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671087738609,"user_tz":300,"elapsed":8298,"user":{"displayName":"Anna Dai","userId":"15954665269866891576"}},"outputId":"17cb01b2-06cd-40c2-ed3f-97aa4ef9f301"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-12-15 07:02:11.600417: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"]}],"source":["!python src/split_data.py "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VLgsm_UzJVY1","outputId":"2ecd947c-aa10-494c-baa2-68be1927fb2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow 2.0 Upgrade Script\n","-----------------------------\n","Converted 1 files\n","Detected 0 issues that require attention\n","--------------------------------------------------------------------------------\n","\n","\n","Make sure to read the detailed log 'report.txt'\n","\n"]}],"source":["# !tf_upgrade_v2 --infile src/replay_buffer.py --outfile src/replay_buffer.py"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"XgiFO1KbJVY1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671087819974,"user_tz":300,"elapsed":81384,"user":{"displayName":"Anna Dai","userId":"15954665269866891576"}},"outputId":"3ebac437-2c2c-44af-f95a-61659de47576"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-12-15 07:02:19.607976: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"]}],"source":["!python src/replay_buffer.py"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8VlFsQYBJVY2","outputId":"d96dcb28-746c-4572-e20c-1c9de3804862","executionInfo":{"status":"ok","timestamp":1671087863386,"user_tz":300,"elapsed":43430,"user":{"displayName":"Anna Dai","userId":"15954665269866891576"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["9.0\n","20.0\n","1.0\n","27.0\n","21.0\n","18.0\n","15.0\n","16.0\n","26.0\n"]}],"source":["!python src/pop.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBxft7R-JVY3"},"outputs":[],"source":["# !tf_upgrade_v2 --infile src/SNQN.py --outfile src/SNQN.py\n","# !tf_upgrade_v2 --infile src/SA2C.py --outfile src/SA2C.py\n","# !tf_upgrade_v2 --infile src/utility.py --outfile src/utility.py\n","# !tf_upgrade_v2 --infile src/SASRecModules.py --outfile src/SASRecModules.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbucQpMx7F7K","outputId":"093bc32b-c48f-47bd-ca9b-6bf738793e4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-12-15 07:12:59.702876: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2022-12-15 07:13:10.328432: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-15 07:13:11.047227: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-12-15 07:13:11.047293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38368 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n","2022-12-15 07:13:11.087336: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n","2022-12-15 07:13:12.585625: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n","2022-12-15 07:13:13.320266: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n","#############################################################\n","total clicks: 112123, total purchase:5259\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 3.000000\n","clicks hr ndcg @ 5 : 0.000089, 0.000054\n","purchase hr and ndcg @5 : 0.000190, 0.000074\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 4.800000\n","clicks hr ndcg @ 10 : 0.000169, 0.000080\n","purchase hr and ndcg @10 : 0.000190, 0.000074\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 8.000000\n","clicks hr ndcg @ 15 : 0.000223, 0.000095\n","purchase hr and ndcg @15 : 0.000570, 0.000176\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11.200000\n","clicks hr ndcg @ 20 : 0.000321, 0.000118\n","purchase hr and ndcg @20 : 0.000761, 0.000220\n","#############################################################\n","the loss in 200th batch is: 10.892766\n","the loss in 400th batch is: 10.656922\n","the loss in 600th batch is: 10.711722\n","the loss in 800th batch is: 10.420089\n","the loss in 1000th batch is: 10.325552\n","the loss in 1200th batch is: 10.223632\n","the loss in 1400th batch is: 10.162954\n","the loss in 1600th batch is: 9.795546\n","the loss in 1800th batch is: 9.611269\n","the loss in 2000th batch is: 9.779029\n","the loss in 2200th batch is: 9.894069\n","the loss in 2400th batch is: 9.743126\n","the loss in 2600th batch is: 9.567203\n","the loss in 2800th batch is: 9.830052\n","the loss in 3000th batch is: 9.372000\n","the loss in 3200th batch is: 9.193812\n","the loss in 3400th batch is: 9.175719\n","the loss in 3600th batch is: 9.092307\n","the loss in 3800th batch is: 8.568467\n","the loss in 4000th batch is: 8.727430\n","#############################################################\n","total clicks: 112123, total purchase:5259\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 6330.000000\n","clicks hr ndcg @ 5 : 0.193359, 0.152160\n","purchase hr and ndcg @5 : 0.379160, 0.324709\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 7269.200000\n","clicks hr ndcg @ 10 : 0.226501, 0.162899\n","purchase hr and ndcg @10 : 0.416429, 0.336787\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7820.800000\n","clicks hr ndcg @ 15 : 0.245703, 0.167988\n","purchase hr and ndcg @15 : 0.439437, 0.342864\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 8175.600000\n","clicks hr ndcg @ 20 : 0.258270, 0.170957\n","purchase hr and ndcg @20 : 0.453318, 0.346142\n","#############################################################\n","the loss in 4200th batch is: 8.534602\n","the loss in 4400th batch is: 8.620985\n","the loss in 4600th batch is: 8.535417\n","the loss in 4800th batch is: 8.489982\n","the loss in 5000th batch is: 7.823396\n","the loss in 5200th batch is: 7.936608\n","the loss in 5400th batch is: 8.017735\n","the loss in 5600th batch is: 8.196262\n","the loss in 5800th batch is: 7.829350\n","the loss in 6000th batch is: 8.113388\n","the loss in 6200th batch is: 7.905000\n","the loss in 6400th batch is: 7.752167\n","the loss in 6600th batch is: 8.141510\n","the loss in 6800th batch is: 7.210954\n","the loss in 7000th batch is: 7.486486\n","the loss in 7200th batch is: 7.377941\n","the loss in 7400th batch is: 7.191810\n","the loss in 7600th batch is: 7.212529\n","the loss in 7800th batch is: 7.332635\n","the loss in 8000th batch is: 7.549317\n","#############################################################\n","total clicks: 112123, total purchase:5259\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8478.200000\n","clicks hr ndcg @ 5 : 0.257226, 0.201006\n","purchase hr and ndcg @5 : 0.515307, 0.441365\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 9724.800000\n","clicks hr ndcg @ 10 : 0.304211, 0.216225\n","purchase hr and ndcg @10 : 0.552006, 0.453230\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 10372.000000\n","clicks hr ndcg @ 15 : 0.329103, 0.222819\n","purchase hr and ndcg @15 : 0.568929, 0.457707\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10831.200000\n","clicks hr ndcg @ 20 : 0.346370, 0.226899\n","purchase hr and ndcg @20 : 0.582620, 0.460954\n","#############################################################\n","the loss in 8200th batch is: 7.165633\n","the loss in 8400th batch is: 7.288446\n","the loss in 8600th batch is: 6.997312\n","the loss in 8800th batch is: 7.215827\n","the loss in 9000th batch is: 7.437542\n","the loss in 9200th batch is: 7.234551\n","the loss in 9400th batch is: 6.860294\n","the loss in 9600th batch is: 6.542135\n","the loss in 9800th batch is: 7.015682\n","the loss in 10000th batch is: 6.262510\n","the loss in 10200th batch is: 6.774211\n","the loss in 10400th batch is: 6.516809\n","the loss in 10600th batch is: 6.688951\n","the loss in 10800th batch is: 6.857430\n","the loss in 11000th batch is: 6.985450\n","the loss in 11200th batch is: 6.793715\n","the loss in 11400th batch is: 6.774787\n","the loss in 11600th batch is: 6.426016\n","the loss in 11800th batch is: 6.370440\n","the loss in 12000th batch is: 6.977374\n","#############################################################\n","total clicks: 112123, total purchase:5259\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9063.200000\n","clicks hr ndcg @ 5 : 0.277294, 0.215358\n","purchase hr and ndcg @5 : 0.540977, 0.461628\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10497.800000\n","clicks hr ndcg @ 10 : 0.329272, 0.232200\n","purchase hr and ndcg @10 : 0.592128, 0.478305\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11278.400000\n","clicks hr ndcg @ 15 : 0.358196, 0.239871\n","purchase hr and ndcg @15 : 0.617228, 0.484941\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11805.400000\n","clicks hr ndcg @ 20 : 0.377773, 0.244498\n","purchase hr and ndcg @20 : 0.633961, 0.488895\n","#############################################################\n","the loss in 12200th batch is: 6.366846\n","the loss in 12400th batch is: 6.571247\n","the loss in 12600th batch is: 6.150367\n","the loss in 12800th batch is: 6.645137\n","the loss in 13000th batch is: 6.053125\n","the loss in 13200th batch is: 6.323468\n","the loss in 13400th batch is: 6.582263\n","the loss in 13600th batch is: 6.378313\n","the loss in 13800th batch is: 5.915146\n","the loss in 14000th batch is: 6.211163\n","the loss in 14200th batch is: 6.695260\n","the loss in 14400th batch is: 6.381785\n","the loss in 14600th batch is: 6.476668\n","the loss in 14800th batch is: 6.382092\n","the loss in 15000th batch is: 5.841011\n","the loss in 15200th batch is: 6.237913\n","the loss in 15400th batch is: 6.036417\n","the loss in 15600th batch is: 6.395456\n","the loss in 15800th batch is: 6.264874\n","the loss in 16000th batch is: 6.101648\n","#############################################################\n","total clicks: 112123, total purchase:5259\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9408.600000\n","clicks hr ndcg @ 5 : 0.286498, 0.222573\n","purchase hr and ndcg @5 : 0.567408, 0.477119\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10894.200000\n","clicks hr ndcg @ 10 : 0.341553, 0.240439\n","purchase hr and ndcg @10 : 0.615136, 0.492637\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11694.000000\n","clicks hr ndcg @ 15 : 0.371333, 0.248340\n","purchase hr and ndcg @15 : 0.640236, 0.499314\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12207.200000\n","clicks hr ndcg @ 20 : 0.391276, 0.253051\n","purchase hr and ndcg @20 : 0.652786, 0.502277\n","#############################################################\n","the loss in 16200th batch is: 5.975156\n","the loss in 16400th batch is: 6.218891\n","the loss in 16600th batch is: 5.972598\n","the loss in 16800th batch is: 6.004962\n","the loss in 17000th batch is: 6.048406\n","the loss in 17200th batch is: 5.986506\n","the loss in 17400th batch is: 6.018816\n","the loss in 17600th batch is: 5.854763\n","the loss in 17800th batch is: 5.897266\n","the loss in 18000th batch is: 5.737123\n","the loss in 18200th batch is: 5.604683\n","the loss in 18400th batch is: 5.922146\n","the loss in 18600th batch is: 5.691145\n","the loss in 18800th batch is: 6.075284\n","the loss in 19000th batch is: 5.566946\n","the loss in 19200th batch is: 6.126355\n","the loss in 19400th batch is: 5.838688\n","the loss in 19600th batch is: 5.605361\n","the loss in 19800th batch is: 5.916121\n","the loss in 20000th batch is: 5.339351\n","#############################################################\n","total clicks: 112123, total purchase:5259\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9564.000000\n","clicks hr ndcg @ 5 : 0.293205, 0.226106\n","purchase hr and ndcg @5 : 0.568359, 0.474270\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11088.400000\n","clicks hr ndcg @ 10 : 0.348920, 0.244167\n","purchase hr and ndcg @10 : 0.620650, 0.491309\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11907.000000\n","clicks hr ndcg @ 15 : 0.379137, 0.252173\n","purchase hr and ndcg @15 : 0.647461, 0.498418\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12442.600000\n","clicks hr ndcg @ 20 : 0.399722, 0.257043\n","purchase hr and ndcg @20 : 0.661533, 0.501726\n","#############################################################\n","the loss in 20200th batch is: 5.691860\n","the loss in 20400th batch is: 5.579550\n","the loss in 20600th batch is: 5.505963\n","the loss in 20800th batch is: 5.958022\n","the loss in 21000th batch is: 5.250834\n","the loss in 21200th batch is: 5.741704\n","the loss in 21400th batch is: 5.875951\n","the loss in 21600th batch is: 5.659566\n","the loss in 21800th batch is: 5.946316\n","the loss in 22000th batch is: 5.750533\n","the loss in 22200th batch is: 5.416817\n","the loss in 22400th batch is: 5.866956\n","the loss in 22600th batch is: 5.857183\n","the loss in 22800th batch is: 5.704191\n","the loss in 23000th batch is: 5.584886\n","the loss in 23200th batch is: 5.304471\n","the loss in 23400th batch is: 5.635213\n","the loss in 23600th batch is: 5.527164\n","the loss in 23800th batch is: 5.302956\n","the loss in 24000th batch is: 5.420955\n","#############################################################\n","total clicks: 112123, total purchase:5259\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9575.000000\n","clicks hr ndcg @ 5 : 0.293963, 0.226263\n","purchase hr and ndcg @5 : 0.567218, 0.470255\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11169.200000\n","clicks hr ndcg @ 10 : 0.351453, 0.244926\n","purchase hr and ndcg @10 : 0.625214, 0.489093\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12003.600000\n","clicks hr ndcg @ 15 : 0.382821, 0.253230\n","purchase hr and ndcg @15 : 0.650124, 0.495699\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12539.600000\n","clicks hr ndcg @ 20 : 0.402888, 0.257970\n","purchase hr and ndcg @20 : 0.666477, 0.499557\n","#############################################################\n","the loss in 24200th batch is: 5.215484\n","the loss in 24400th batch is: 5.281558\n","the loss in 24600th batch is: 5.744768\n","the loss in 24800th batch is: 5.799229\n","the loss in 25000th batch is: 5.225246\n","the loss in 25200th batch is: 5.462291\n","the loss in 25400th batch is: 5.169377\n","the loss in 25600th batch is: 5.548569\n","the loss in 25800th batch is: 5.725362\n","the loss in 26000th batch is: 5.091343\n","the loss in 26200th batch is: 5.814729\n","the loss in 26400th batch is: 5.506870\n","the loss in 26600th batch is: 5.663353\n","the loss in 26800th batch is: 5.129343\n","the loss in 27000th batch is: 5.263650\n","the loss in 27200th batch is: 5.427007\n","the loss in 27400th batch is: 5.237967\n","the loss in 27600th batch is: 5.311507\n","the loss in 27800th batch is: 4.948241\n","the loss in 28000th batch is: 5.326806\n","#############################################################\n","total clicks: 112123, total purchase:5259\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9579.800000\n","clicks hr ndcg @ 5 : 0.294801, 0.225336\n","purchase hr and ndcg @5 : 0.564556, 0.466803\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11233.400000\n","clicks hr ndcg @ 10 : 0.354004, 0.244542\n","purchase hr and ndcg @10 : 0.626545, 0.486843\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 12063.000000\n","clicks hr ndcg @ 15 : 0.385068, 0.252777\n","purchase hr and ndcg @15 : 0.651835, 0.493517\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12601.400000\n","clicks hr ndcg @ 20 : 0.405421, 0.257587\n","purchase hr and ndcg @20 : 0.667427, 0.497209\n","#############################################################\n","the loss in 28200th batch is: 5.609748\n","the loss in 28400th batch is: 5.528011\n","the loss in 28600th batch is: 5.657065\n","the loss in 28800th batch is: 5.208795\n","the loss in 29000th batch is: 4.968859\n","the loss in 29200th batch is: 5.228127\n","the loss in 29400th batch is: 5.361069\n","the loss in 29600th batch is: 5.216255\n","the loss in 29800th batch is: 5.501654\n","the loss in 30000th batch is: 5.362433\n","the loss in 30200th batch is: 5.684625\n","the loss in 30400th batch is: 5.293470\n","the loss in 30600th batch is: 5.305597\n","the loss in 30800th batch is: 4.972438\n","the loss in 31000th batch is: 5.035142\n","the loss in 31200th batch is: 5.241279\n","the loss in 31400th batch is: 5.281523\n","the loss in 31600th batch is: 5.401199\n","the loss in 31800th batch is: 5.586151\n","the loss in 32000th batch is: 4.991130\n","#############################################################\n","total clicks: 112123, total purchase:5259\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9488.600000\n","clicks hr ndcg @ 5 : 0.293410, 0.224962\n","purchase hr and ndcg @5 : 0.553147, 0.456141\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 11080.000000\n","clicks hr ndcg @ 10 : 0.350196, 0.243404\n","purchase hr and ndcg @10 : 0.613615, 0.475768\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11924.200000\n","clicks hr ndcg @ 15 : 0.381643, 0.251734\n","purchase hr and ndcg @15 : 0.640046, 0.482753\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 12495.000000\n","clicks hr ndcg @ 20 : 0.402906, 0.256757\n","purchase hr and ndcg @20 : 0.657920, 0.486955\n","#############################################################\n","the loss in 32200th batch is: 5.463961\n","the loss in 32400th batch is: 5.259795\n","the loss in 32600th batch is: 5.115477\n","the loss in 32800th batch is: 5.504286\n","the loss in 33000th batch is: 5.197443\n","the loss in 33200th batch is: 5.409476\n","the loss in 33400th batch is: 5.661449\n","the loss in 33600th batch is: 5.163372\n","the loss in 33800th batch is: 4.950808\n","the loss in 34000th batch is: 5.364692\n","the loss in 34200th batch is: 5.355019\n","the loss in 34400th batch is: 5.319323\n","the loss in 34600th batch is: 5.435129\n","the loss in 34800th batch is: 5.114035\n","the loss in 35000th batch is: 5.203579\n","the loss in 35200th batch is: 5.125266\n","the loss in 35400th batch is: 4.982992\n","the loss in 35600th batch is: 5.230583\n","the loss in 35800th batch is: 4.973299\n","the loss in 36000th batch is: 4.772042\n"]}],"source":["import time\n","\n","tac = time.time()\n","\n","!python src/SNQN.py --model=SASRec --epoch=15\n","\n","tic = time.time()\n","print(f\"Time to run 15 epochs: {np.round((tic-tac)/60,2)} minutes\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLINbOJ-JVY3"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"}}},"nbformat":4,"nbformat_minor":0}